{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9171fade-bcc7-4803-88ba-e60df4813fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Ensure CUDA and cuDNN are correctly installed.\n",
      "0    cv-corpus-7.0-singleword/ta\\clips\\common_voice...\n",
      "1    cv-corpus-7.0-singleword/ta\\clips\\common_voice...\n",
      "2    cv-corpus-7.0-singleword/ta\\clips\\common_voice...\n",
      "3    cv-corpus-7.0-singleword/ta\\clips\\common_voice...\n",
      "4    cv-corpus-7.0-singleword/ta\\clips\\common_voice...\n",
      "Name: path, dtype: object\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22693174.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22693174.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22064618.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22064618.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21711106.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21711106.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21714254.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21714254.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21721820.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21721820.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416375.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416375.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416385.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416385.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22474512.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22474512.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22474516.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22474516.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21829428.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21829428.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21829429.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21829429.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410476.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410476.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410478.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410478.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21746221.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21746221.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21746487.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21746487.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21689632.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21689632.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21689633.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21689633.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21708919.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21708919.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702617.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702617.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702619.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702619.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702621.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702621.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702650.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22702650.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414865.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414865.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414866.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414866.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414867.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414867.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414868.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414868.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413748.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413748.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413750.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413750.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413751.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413751.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413752.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22413752.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410619.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410619.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410622.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410622.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410624.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410624.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410625.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410625.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410626.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410626.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119937.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119937.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119939.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119939.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119940.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119940.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119942.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119942.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119947.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22119947.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414714.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414714.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414715.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414715.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414716.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414716.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414717.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414717.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414718.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22414718.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024481.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024481.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024482.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024482.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024483.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024483.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024484.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024484.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024485.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22024485.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410677.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410677.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410680.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410680.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410684.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410684.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410685.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410685.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410686.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410686.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621534.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621534.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621539.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621539.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621541.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621541.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621914.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621914.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621918.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621918.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621937.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621937.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621938.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621938.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621940.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22621940.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534431.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534431.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534433.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534433.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534435.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534435.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534437.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534437.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534457.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534457.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534458.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534458.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534462.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534462.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534464.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534464.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136193.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136193.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136198.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136198.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136201.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136201.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136207.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136207.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136210.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136210.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136222.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136222.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136228.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136228.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136231.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136231.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136234.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22136234.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435892.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435892.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435893.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435893.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435894.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435894.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435895.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435895.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435896.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435896.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435897.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435897.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435898.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435898.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435899.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435899.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435901.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22435901.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416780.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416780.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416781.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416781.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416782.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416782.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416783.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416783.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416784.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416784.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416786.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416786.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416787.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416787.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416788.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416788.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416789.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22416789.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388277.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388277.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388278.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388278.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388279.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388279.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388280.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388280.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388282.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388282.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388283.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388283.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388285.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388285.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388286.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388286.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388289.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388289.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388291.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22388291.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971674.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971674.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971675.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971675.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971677.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971677.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971680.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971680.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971682.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971682.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971724.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971724.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971725.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971725.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971726.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971726.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971728.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971728.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971730.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21971730.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21843468.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21843468.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896817.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896817.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896818.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896818.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896819.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896819.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896820.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896820.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896823.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896823.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896824.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896824.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896825.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896825.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896827.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896827.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896828.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896828.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896829.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_21896829.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018487.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018487.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018493.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018493.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018498.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018498.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018500.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018500.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018501.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018501.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018503.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018503.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018504.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018504.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018507.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018507.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018509.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018509.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018511.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018511.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018552.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22018552.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090931.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090931.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090932.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090932.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090933.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090933.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090934.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090934.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090936.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090936.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090955.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090955.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090960.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090960.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090963.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090963.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090966.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090966.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090969.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22090969.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22091102.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22091102.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060821.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060821.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060822.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060822.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060823.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060823.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060824.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060824.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060825.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060825.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060846.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060846.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060847.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060847.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060848.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060848.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060849.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060849.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060850.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060850.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060975.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22060975.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546148.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546148.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546149.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546149.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546150.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546150.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546151.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546151.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546152.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546152.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546154.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546154.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546155.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546155.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546156.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546156.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546158.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546158.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546167.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546167.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546168.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546168.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546169.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22546169.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534586.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534586.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534589.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534589.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534598.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534598.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534600.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534600.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534730.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534730.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534743.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534743.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534744.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534744.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534745.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534745.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534747.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534747.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534789.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534789.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534792.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534792.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534916.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22534916.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102686.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102686.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102688.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102688.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102691.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102691.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102692.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102692.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102749.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102749.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102750.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102750.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102751.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102751.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102752.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102752.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102753.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102753.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102793.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102793.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102794.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102794.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102795.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22102795.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410243.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410243.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410248.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410248.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410250.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410250.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410251.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410251.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410263.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410263.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410264.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410264.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410265.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410265.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410266.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410266.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410267.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410267.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410295.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410295.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410296.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410296.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410298.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410298.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410438.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22410438.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415141.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415141.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415405.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415405.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415406.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415406.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415408.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415408.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415409.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415409.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415425.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415425.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415426.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415426.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415427.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415427.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415428.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415428.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415429.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22415429.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22478932.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22478932.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22478933.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22478933.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22478935.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22478935.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280770.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280770.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280772.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280772.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280773.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280773.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280774.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280774.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280775.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280775.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280776.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280776.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280777.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280777.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280778.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280778.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280779.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280779.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280780.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280780.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280786.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280786.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280787.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280787.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280788.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280788.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280789.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22280789.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305157.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305157.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305159.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305159.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305161.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305161.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305162.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305162.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305164.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305164.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305184.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305184.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305185.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305185.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305186.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305186.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305187.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305187.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305188.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305188.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305204.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305204.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305206.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305206.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305207.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305207.mp3: (128, 216, 3)\n",
      "Loading file: cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305209.mp3\n",
      "Spectrogram shape for cv-corpus-7.0-singleword/ta\\clips\\common_voice_ta_22305209.mp3: (128, 216, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISHIT\\AppData\\Local\\Temp\\ipykernel_19284\\1359357741.py:73: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_66                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_67                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35840</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,416,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_66 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_66                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)    │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_67                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35840\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m18,416,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,690,624</span> (78.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,690,624\u001b[0m (78.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,432,640</span> (70.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,432,640\u001b[0m (70.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step\n",
      "Embeddings: (252, 128)\n",
      "\n",
      "Embeddings: [[0.03184887 0.         0.         ... 0.         0.21454336 0.21564873]\n",
      " [0.18957488 0.         0.01428142 ... 0.         0.69044936 0.        ]\n",
      " [0.13938804 0.04130739 0.         ... 0.         0.5604585  0.02380553]\n",
      " ...\n",
      " [0.1133021  0.         0.         ... 0.         0.45789328 0.        ]\n",
      " [0.         0.         0.02190065 ... 0.00975258 0.21257503 0.05762592]\n",
      " [0.02095847 0.         0.         ... 0.         0.7436626  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure GPU is used\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(f\"Using GPU: {physical_devices[0]}\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"No GPU found. Ensure CUDA and cuDNN are correctly installed.\")\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 22050  # Sample rate for audio\n",
    "N_MELS = 128         # Number of mel bands\n",
    "DURATION = 2         # Fixed audio duration in seconds\n",
    "HOP_LENGTH = 512     # Hop length for spectrogram\n",
    "INPUT_SHAPE = (None, 128, 216, 3) # Input shape for MobileNetV2 (3 channels)\n",
    "INPUT_SIZE = 82944\n",
    "LSTM_UNITS = 128     # LSTM units\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_audio(file_path, sample_rate=SAMPLE_RATE, duration=DURATION):\n",
    "    \"\"\"Load audio file and convert to mel spectrogram.\"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, hop_length=HOP_LENGTH)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Pad or truncate the spectrogram to match the desired shape (N_MELS, 216)\n",
    "    target_length = 216  # Set the desired number of time steps\n",
    "    if mel_spectrogram_db.shape[1] < target_length:\n",
    "        # Pad the spectrogram with zeros if it's shorter\n",
    "        pad_width = target_length - mel_spectrogram_db.shape[1]\n",
    "        mel_spectrogram_db = np.pad(mel_spectrogram_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    elif mel_spectrogram_db.shape[1] > target_length:\n",
    "        # Truncate the spectrogram if it's longer\n",
    "        mel_spectrogram_db = mel_spectrogram_db[:, :target_length]\n",
    "    \n",
    "    # Convert to 3 channels by repeating the single channel spectrogram\n",
    "    mel_spectrogram_db_3_channels = np.repeat(mel_spectrogram_db[:, :, np.newaxis], 3, axis=-1)\n",
    "    \n",
    "    return mel_spectrogram_db_3_channels\n",
    "\n",
    "# Dataset Loader with Debugging\n",
    "def load_dataset(file_paths):\n",
    "    \"\"\"Load dataset and preprocess into spectrograms.\"\"\"\n",
    "    spectrograms = []\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Loading file: {file_path}\")  # Debugging: print the file being processed\n",
    "        if file_path.endswith((\".mp3\", \".wav\", \".flac\")):  # Check for multiple formats\n",
    "            if os.path.exists(file_path):\n",
    "                spectrogram = preprocess_audio(file_path)\n",
    "                print(f\"Spectrogram shape for {file_path}: {spectrogram.shape}\")  # Debugging: check shape\n",
    "                spectrograms.append(spectrogram)\n",
    "            else:\n",
    "                print(f\"File does not exist: {file_path}\")\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file type: {file_path}\")\n",
    "    \n",
    "    # Convert list to numpy array\n",
    "    return np.array(spectrograms)\n",
    "\n",
    "# MobileNetV2 for Feature Extraction\n",
    "def build_feature_extractor(input_shape):\n",
    "    \"\"\"Build MobileNetV2 feature extractor.\"\"\"\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "    base_model.trainable = False  # Freeze weights\n",
    "    return base_model\n",
    "\n",
    "# Full Model\n",
    "def build_model(input_shape, lstm_units):\n",
    "    \"\"\"Build the full model.\"\"\"\n",
    "    input_layer = Input(shape=(None, 128, 216, 3))\n",
    "   \n",
    "    # Feature extraction with MobileNetV2\n",
    "    feature_extractor = build_feature_extractor(input_shape)\n",
    "    features = TimeDistributed(feature_extractor)(input_layer)  # Apply feature extractor for each time step\n",
    "    flattened_features = TimeDistributed(Flatten())(features)   # Flatten features for LSTM\n",
    "   \n",
    "    # Temporal modeling with LSTM\n",
    "    lstm_output = LSTM(lstm_units, return_sequences=False)(flattened_features)\n",
    "   \n",
    "    # Output embedding\n",
    "    output_layer = Dense(128, activation=\"relu\", name=\"embedding\")(lstm_output)\n",
    "   \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Example Workflow\n",
    "dataset_path = \"cv-corpus-7.0-singleword/ta\"  # Update this to the location of your dataset\n",
    "audio_files = os.path.join(dataset_path, \"clips\")\n",
    "metadata_file = os.path.join(dataset_path, \"validated.tsv\")  # Replace if different\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_file, sep=\"\\t\")\n",
    "metadata[\"path\"] = metadata[\"path\"].apply(lambda x: os.path.join(audio_files, x))\n",
    "\n",
    "# Print first few paths for debugging\n",
    "print(metadata[\"path\"].head())\n",
    "\n",
    "# # Load spectrograms (pass individual file paths to load_dataset)\n",
    "# spectrograms = load_dataset(metadata[\"path\"].values)\n",
    "\n",
    "# # Normalize Spectrograms\n",
    "# spectrograms = spectrograms / np.max(spectrograms)\n",
    "\n",
    "# # Add time dimension (even if only 1 time step)\n",
    "# spectrograms = np.expand_dims(spectrograms, axis=1)\n",
    "\n",
    "# # Build and Compile Model\n",
    "\n",
    "# model = build_model((128, 216, 3), LSTM_UNITS)  # Adjust input shape to (time_steps, height, width, channels)\n",
    "# model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "# model.summary()\n",
    "\n",
    "# Load spectrograms (pass individual file paths to load_dataset)\n",
    "spectrograms = load_dataset(metadata[\"path\"].values)\n",
    "\n",
    "# Normalize Spectrograms\n",
    "spectrograms = spectrograms / np.max(spectrograms)\n",
    "\n",
    "# Add time dimension (even if only 1 time step)\n",
    "spectrograms = np.expand_dims(spectrograms, axis=1)\n",
    "\n",
    "# Build and Compile Model\n",
    "model = build_model((128, 216, 3), LSTM_UNITS)  # Adjust input shape to (time_steps, height, width, channels)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "# Generate Embeddings\n",
    "embeddings = model.predict(spectrograms, batch_size=8)  # Adjust batch size if needed\n",
    "print(\"Embeddings:\", embeddings.shape)\n",
    "print(\"\\nEmbeddings:\", embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a205e10e-a4e4-4341-a66b-28215b46aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISHIT\\AppData\\Local\\Temp\\ipykernel_19284\\1359357741.py:73: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10, Meta Loss: 0.7100, Accuracy: 1.0000\n",
      "Iteration 2/10, Meta Loss: 0.0010, Accuracy: 1.0000\n",
      "Iteration 3/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 4/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 5/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 6/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 7/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 8/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 9/10, Meta Loss: 0.0000, Accuracy: 1.0000\n",
      "Iteration 10/10, Meta Loss: 0.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define MAML loss\n",
    "def maml_loss(y_true, y_pred):\n",
    "    \"\"\"MAML loss function: Negative log-likelihood loss.\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.int32)  # Ensure y_true is in integer format\n",
    "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "\n",
    "# Preprocess labels into integers\n",
    "def preprocess_labels(labels):\n",
    "    \"\"\"Convert string labels to integers.\"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    return label_encoder.fit_transform(labels)\n",
    "\n",
    "# Generate spectrogram from audio file\n",
    "def generate_spectrogram(file_path, n_mels=128, hop_length=512, n_fft=2048, duration=None):\n",
    "    audio, sr = librosa.load(file_path, sr=None, duration=duration)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels\n",
    "    )\n",
    "    log_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    log_spectrogram = (log_spectrogram - log_spectrogram.min()) / (log_spectrogram.max() - log_spectrogram.min())\n",
    "    log_spectrogram = np.stack([log_spectrogram] * 3, axis=-1)\n",
    "    return tf.convert_to_tensor(log_spectrogram, dtype=tf.float32)\n",
    "\n",
    "# Preprocess a batch of audio files into spectrogram tensors\n",
    "def preprocess_batch(file_paths):\n",
    "    tensors = []\n",
    "    for file_path in file_paths:\n",
    "        spectrogram = generate_spectrogram(file_path)\n",
    "        resized_spectrogram = tf.image.resize(spectrogram, (128, 216))\n",
    "        tensors.append(resized_spectrogram)\n",
    "    batch_tensor = tf.stack(tensors)\n",
    "    return tf.expand_dims(batch_tensor, axis=1)  # Adds a temporal dimension\n",
    "\n",
    "# MAML training step: Apply gradient updates to the model parameters\n",
    "def maml_train_step(model, support_set, query_set, learning_rate=0.01):\n",
    "    support_set_tensors = preprocess_batch(support_set[\"files\"])\n",
    "    query_set_tensors = preprocess_batch(query_set[\"files\"])\n",
    "    \n",
    "    support_labels = preprocess_labels(support_set['labels'])\n",
    "    query_labels = preprocess_labels(query_set['labels'])\n",
    "    \n",
    "    support_labels = tf.convert_to_tensor(support_labels)\n",
    "    query_labels = tf.convert_to_tensor(query_labels)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        support_embeddings = model(support_set_tensors)\n",
    "        support_loss = maml_loss(support_labels, support_embeddings)\n",
    "    \n",
    "    gradients = tape.gradient(support_loss, model.trainable_variables)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return support_loss, query_set_tensors, query_labels\n",
    "\n",
    "# Prototypical Networks loss function\n",
    "def prototypical_loss(query_embeddings, query_labels, prototypes):\n",
    "    distances = np.linalg.norm(query_embeddings[:, np.newaxis] - prototypes, axis=-1)\n",
    "    predictions = tf.nn.softmax(-distances)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=query_labels, logits=predictions))\n",
    "    return loss\n",
    "\n",
    "# Build the model (MobileNetV2 + LSTM)\n",
    "def build_model(input_shape, lstm_units):\n",
    "    input_layer = Input(shape=(None, 128, 216, 3))\n",
    "    feature_extractor = build_feature_extractor(input_shape)\n",
    "    features = TimeDistributed(feature_extractor)(input_layer)\n",
    "    flattened_features = TimeDistributed(Flatten())(features)\n",
    "    lstm_output = LSTM(lstm_units, return_sequences=False)(flattened_features)\n",
    "    output_layer = Dense(128, activation=\"relu\", name=\"embedding\")(lstm_output)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Meta-Training Loop (MAML)\n",
    "def meta_train(model, dataset, num_tasks, num_shots, num_query, meta_iterations=10):\n",
    "    dataset = list(dataset)\n",
    "    available_tasks = len(dataset)\n",
    "    if num_tasks > available_tasks:\n",
    "        num_tasks = available_tasks\n",
    "    \n",
    "    for iteration in range(meta_iterations):\n",
    "        tasks = random.sample(dataset, num_tasks)\n",
    "        meta_loss = 0\n",
    "        total_accuracy = 0  # Initialize total accuracy\n",
    "        \n",
    "        for task in tasks:\n",
    "            support_set = task['support']\n",
    "            query_set = task['query']\n",
    "            \n",
    "            task_loss, query_set_tensors, query_labels = maml_train_step(model, support_set, query_set)\n",
    "            meta_loss += task_loss\n",
    "            \n",
    "            # Compute query embeddings\n",
    "            query_embeddings = model(query_set_tensors)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predicted_labels = np.argmax(query_embeddings, axis=-1)\n",
    "            accuracy = np.mean(np.equal(predicted_labels, query_labels))\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "        # Average loss and accuracy over tasks\n",
    "        meta_loss /= num_tasks\n",
    "        total_accuracy /= num_tasks\n",
    "        \n",
    "        print(f\"Iteration {iteration + 1}/{meta_iterations}, Meta Loss: {meta_loss:.4f}, Accuracy: {total_accuracy:.4f}\")\n",
    "\n",
    "# Prepare the dataset for few-shot learning\n",
    "def prepare_few_shot_dataset(audio_files, labels, num_shots, num_query):\n",
    "    dataset = []\n",
    "    unique_labels = np.unique(labels)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        class_files = [f for f, l in zip(audio_files, labels) if l == label]\n",
    "        \n",
    "        if len(class_files) >= num_shots + num_query:\n",
    "            sampled_files = random.sample(class_files, num_shots + num_query)\n",
    "            support_set = {\"files\": sampled_files[:num_shots], \"labels\": [label] * num_shots}\n",
    "            query_set = {\"files\": sampled_files[num_shots:], \"labels\": [label] * num_query}\n",
    "            dataset.append({\"support\": support_set, \"query\": query_set})\n",
    "        else:\n",
    "            num_shots_adjusted = max(1, len(class_files) // 2)\n",
    "            num_query_adjusted = len(class_files) - num_shots_adjusted\n",
    "            sampled_files = class_files\n",
    "            support_set = {\"files\": sampled_files[:num_shots_adjusted], \"labels\": [label] * num_shots_adjusted}\n",
    "            query_set = {\"files\": sampled_files[num_shots_adjusted:], \"labels\": [label] * num_query_adjusted}\n",
    "            dataset.append({\"support\": support_set, \"query\": query_set})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Prepare dataset\n",
    "audio_files = metadata[\"path\"].values\n",
    "labels = metadata[\"sentence\"].apply(lambda x: x.split()[0]).values\n",
    "\n",
    "class_to_keyword, keyword_to_class = create_class_to_keyword_mapping(labels)\n",
    "num_shots = 5\n",
    "num_query = 15\n",
    "\n",
    "dataset = prepare_few_shot_dataset(audio_files, labels, num_shots, num_query)\n",
    "num_tasks = len(dataset)\n",
    "\n",
    "# Check if there are tasks available\n",
    "if num_tasks > 0:\n",
    "    model = build_model((128, 216, 3), lstm_units=128)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])\n",
    "    \n",
    "    # Meta-training\n",
    "    meta_train(model, dataset, num_tasks, num_shots, num_query)\n",
    "else:\n",
    "    print(\"No tasks available for meta-training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8c9d652b-10c8-4db1-a942-1ecf3703e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found audio files: ['cv-corpus-7.0-singleword/taFEW\\\\common_voice_ta_21689633.mp3']\n",
      "Shape of embeddings: (1, 128)\n",
      "Shape of labels: 1\n",
      "Query Set Shape: (1, 1, 128, 216, 3)\n",
      "Prototypes Shape: (14, 128)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "Predicted Keywords: ['ஃபயர்ஃபாக்ஸ்'], Loss: 20.850296020507812\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def process_audio(file_path, sr=16000, n_mels=64, n_fft=2048, hop_length=512, win_length=2048):\n",
    "    \"\"\"\n",
    "    Load an audio file and convert it into a Mel spectrogram.\n",
    "    \n",
    "    Args:\n",
    "    - file_path: Path to the audio file.\n",
    "    - sr: Sampling rate.\n",
    "    - n_mels: Number of Mel bands.\n",
    "    - n_fft: Number of FFT points.\n",
    "    - hop_length: Hop length for the STFT.\n",
    "    - win_length: Window length for the STFT.\n",
    "\n",
    "    Returns:\n",
    "    - Mel spectrogram of the audio.\n",
    "    \"\"\"\n",
    "    # Load the audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=sr)\n",
    "    \n",
    "    # Generate the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft,\n",
    "                                                     hop_length=hop_length, win_length=win_length)\n",
    "    \n",
    "    # Convert the Mel spectrogram to decibels (log scale)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Optionally, resize the spectrogram to a fixed shape (e.g., 128x216)\n",
    "    mel_spectrogram_resized = np.resize(mel_spectrogram_db, (128, 216))\n",
    "    \n",
    "    # Add the channel dimension (for 3-channel input)\n",
    "    mel_spectrogram_resized = np.expand_dims(mel_spectrogram_resized, axis=-1)  # Adds a channel dimension (e.g., (128, 216, 1))\n",
    "    mel_spectrogram_resized = np.repeat(mel_spectrogram_resized, 3, axis=-1)  # Repeat the single channel 3 times to simulate RGB\n",
    "    \n",
    "    return mel_spectrogram_resized\n",
    "\n",
    "# Function to load and preprocess these files\n",
    "def load_dataset(file_paths):\n",
    "    dataset = []\n",
    "    for file in file_paths:\n",
    "        # Process each audio file and generate spectrogram\n",
    "        spectrogram = process_audio(file)\n",
    "        dataset.append(spectrogram)\n",
    "    return np.array(dataset)  # Convert to numpy array for consistency\n",
    "# Example: Define the compute_prototypes function (ensure it's defined somewhere in your code)\n",
    "def compute_prototypes(embeddings, labels, num_classes):\n",
    "    prototypes = []\n",
    "    for i in range(num_classes):\n",
    "        class_embeddings = embeddings[labels == i]  # Select embeddings for each class\n",
    "        if class_embeddings.size > 0:  # Ensure embeddings exist for the class\n",
    "            prototypes.append(np.mean(class_embeddings, axis=0))  # Mean embedding\n",
    "        else:\n",
    "            prototypes.append(np.zeros(embeddings.shape[1]))  # Placeholder prototype\n",
    "    return np.array(prototypes)\n",
    "\n",
    "\n",
    "def few_shot_inference(model, query_set, prototypes):\n",
    "    predictions = []\n",
    "    loss = 0.0\n",
    "    \n",
    "    # Pass the entire query set to the model\n",
    "    query_embeddings = model.predict(query_set)  # Shape: (batch_size, embedding_dim)\n",
    "    \n",
    "    # Compute distances and predictions for each query embedding\n",
    "    for query_embedding in query_embeddings:\n",
    "        distances = np.linalg.norm(prototypes - query_embedding, axis=1)  # Euclidean distance\n",
    "        prediction = np.argmin(distances)  # Closest prototype\n",
    "        predictions.append(prediction)\n",
    "        loss += np.min(distances)  # Sum of distances as the loss\n",
    "        #print(\"query_embedding\",query_embedding)\n",
    "        #print(\"distances\",distances)\n",
    "    return predictions, loss\n",
    "\n",
    "def few_shot_inference_with_keywords(model, query_set, prototypes, class_to_keyword):\n",
    "    \"\"\"\n",
    "    Perform few-shot inference and convert numeric predictions to keywords.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained model for embeddings.\n",
    "    - query_set: Query dataset.\n",
    "    - prototypes: Class prototypes.\n",
    "    - class_to_keyword: Mapping from class indices to keywords.\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted keywords.\n",
    "    - loss: Total loss for the query set.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    loss = 0.0\n",
    "\n",
    "    # Get embeddings for the query set\n",
    "    query_embeddings = model.predict(query_set)  # Shape: (batch_size, embedding_dim)\n",
    "    \n",
    "    for query_embedding in query_embeddings:\n",
    "        # Compute distances and find the closest prototype\n",
    "        distances = np.linalg.norm(prototypes - query_embedding, axis=1)\n",
    "        predicted_index = np.argmin(distances)  # Closest prototype index\n",
    "        predictions.append(class_to_keyword[predicted_index])  # Map to keyword\n",
    "        loss += np.min(distances)  # Sum of distances as the loss\n",
    "\n",
    "    return predictions, loss\n",
    "\n",
    "\n",
    "# Assuming this is the path where your audio files are stored\n",
    "audio_folder_path = \"cv-corpus-7.0-singleword/taFEW\"  # Update this to the location of your dataset\n",
    "\n",
    "# Get all .mp3 files in the folder\n",
    "audio_files = glob.glob(os.path.join(audio_folder_path, \"*.mp3\"))\n",
    "\n",
    "# Print the list of audio files to verify\n",
    "print(\"Found audio files:\", audio_files)\n",
    "\n",
    "# Load the query set for the new keywords\n",
    "file_path =  preprocess_batch(audio_files)\n",
    "#print(\"file\",file_path.shape)\n",
    "new_keyword_query_set = load_dataset(audio_files)\n",
    "#print(new_keyword_query_set.shape)\n",
    "num_classes = len(np.unique(labels))  \n",
    "\n",
    "# Example: Ensure the embeddings and labels are aligned\n",
    "# Add a sequence dimension (e.g., sequence length = 1 for single input sequences)\n",
    "new_keyword_query_set = np.expand_dims(new_keyword_query_set, axis=1)  # Shape: (batch_size, sequence_length, 128, 216, 3)\n",
    "#print(\"new_keyword_query_set\",new_keyword_query_set)\n",
    "embeddings = model(new_keyword_query_set)  # Get embeddings for the audio files\n",
    "\n",
    "# Ensure embeddings are numpy arrays\n",
    "embeddings = np.array(embeddings)\n",
    "# Print shapes to debug\n",
    "\n",
    "# Example: Ensure labels match the length of embeddings\n",
    "# If the embeddings are outputting a different number of samples, adjust labels accordingly\n",
    "labels = labels[:len(embeddings)]  # This is an example of truncating labels to match embeddings\n",
    "\n",
    "# If embeddings are not 2D (samples, embedding_dim), check how many samples are being returned\n",
    "# This can help identify if some embeddings were skipped\n",
    "\n",
    "# Make sure embeddings and labels have the same length\n",
    "#assert len(embeddings) == len(labels), \"Mismatch between number of embeddings and labels\"\n",
    "\n",
    "# Compute prototypes\n",
    "prototypes = compute_prototypes(embeddings, labels, num_classes)\n",
    "print(\"Shape of embeddings:\", embeddings.shape)\n",
    "print(\"Shape of labels:\", len(labels))\n",
    "print(\"Query Set Shape:\", new_keyword_query_set.shape)\n",
    "print(\"Prototypes Shape:\", prototypes.shape)\n",
    "\n",
    "predicted_keywords, loss = few_shot_inference_with_keywords(model, new_keyword_query_set, prototypes, class_to_keyword)\n",
    "\n",
    "print(f\"Predicted Keywords: {predicted_keywords}, Loss: {loss}\")\n",
    "#நான்கு ஒன்று ஒன்று"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "13d441d5-2308-4667-8b0f-19f3ec4b680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'ஒன்று' has 0 files.\n",
      "Total tasks in dataset: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISHIT\\AppData\\Local\\Temp\\ipykernel_19284\\2144257536.py:24: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, _ = librosa.load(file_path, sr=sr)\n",
      "C:\\Users\\NISHIT\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'c': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[253], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m dataset, class_to_keyword, keyword_to_class \u001b[38;5;241m=\u001b[39m prepare_dataset(audio_folder_path, labels, num_shots, num_query)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Load the query set (new audio files)\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m new_keyword_query_set \u001b[38;5;241m=\u001b[39m load_dataset(audio_folder_path)  \u001b[38;5;66;03m# Load new query set\u001b[39;00m\n\u001b[0;32m    120\u001b[0m new_keyword_query_set \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(new_keyword_query_set, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, sequence_length, 128, 216, 3)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Assuming you already have a trained model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[253], line 46\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(file_paths)\u001b[0m\n\u001b[0;32m     44\u001b[0m dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[1;32m---> 46\u001b[0m     spectrogram \u001b[38;5;241m=\u001b[39m process_audio(file)\n\u001b[0;32m     47\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mappend(spectrogram)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(dataset)\n",
      "Cell \u001b[1;32mIn[253], line 24\u001b[0m, in \u001b[0;36mprocess_audio\u001b[1;34m(file_path, sr, n_mels, n_fft, hop_length, win_length)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mLoad an audio file and convert it into a Mel spectrogram.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m- Mel spectrogram of the audio.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Load the audio file using librosa\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m audio, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file_path, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Generate the Mel spectrogram\u001b[39;00m\n\u001b[0;32m     27\u001b[0m mel_spectrogram \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr, n_mels\u001b[38;5;241m=\u001b[39mn_mels, n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[0;32m     28\u001b[0m                                                  hop_length\u001b[38;5;241m=\u001b[39mhop_length, win_length\u001b[38;5;241m=\u001b[39mwin_length)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def process_audio(file_path, sr=16000, n_mels=64, n_fft=2048, hop_length=512, win_length=2048):\n",
    "    \"\"\"\n",
    "    Load an audio file and convert it into a Mel spectrogram.\n",
    "    \n",
    "    Args:\n",
    "    - file_path: Path to the audio file.\n",
    "    - sr: Sampling rate.\n",
    "    - n_mels: Number of Mel bands.\n",
    "    - n_fft: Number of FFT points.\n",
    "    - hop_length: Hop length for the STFT.\n",
    "    - win_length: Window length for the STFT.\n",
    "\n",
    "    Returns:\n",
    "    - Mel spectrogram of the audio.\n",
    "    \"\"\"\n",
    "    # Load the audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=sr)\n",
    "    \n",
    "    # Generate the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft,\n",
    "                                                     hop_length=hop_length, win_length=win_length)\n",
    "    \n",
    "    # Convert the Mel spectrogram to decibels (log scale)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Optionally, resize the spectrogram to a fixed shape (e.g., 128x216)\n",
    "    mel_spectrogram_resized = np.resize(mel_spectrogram_db, (128, 216))\n",
    "    \n",
    "    # Add the channel dimension (for 3-channel input)\n",
    "    mel_spectrogram_resized = np.expand_dims(mel_spectrogram_resized, axis=-1)  # Adds a channel dimension (e.g., (128, 216, 1))\n",
    "    mel_spectrogram_resized = np.repeat(mel_spectrogram_resized, 3, axis=-1)  # Repeat the single channel 3 times to simulate RGB\n",
    "    \n",
    "    return mel_spectrogram_resized\n",
    "\n",
    "def load_dataset(file_paths):\n",
    "    \"\"\"Preprocess a batch of audio files into spectrogram tensors.\"\"\"\n",
    "    dataset = []\n",
    "    for file in file_paths:\n",
    "        spectrogram = process_audio(file)\n",
    "        dataset.append(spectrogram)\n",
    "    return np.array(dataset)  # Convert to numpy array for consistency\n",
    "\n",
    "def compute_prototypes(embeddings, labels, num_classes):\n",
    "    \"\"\"Compute the prototypes for each class as the mean of embeddings.\"\"\"\n",
    "    prototypes = []\n",
    "    for i in range(num_classes):\n",
    "        class_embeddings = embeddings[labels == i]  # Select embeddings for each class\n",
    "        if class_embeddings.size > 0:\n",
    "            prototypes.append(np.mean(class_embeddings, axis=0))  # Mean embedding\n",
    "        else:\n",
    "            prototypes.append(np.zeros(embeddings.shape[1]))  # Placeholder for empty class\n",
    "    return np.array(prototypes)\n",
    "\n",
    "def few_shot_inference_with_keywords(model, query_set, prototypes, class_to_keyword):\n",
    "    \"\"\"\n",
    "    Perform few-shot inference and convert numeric predictions to keywords.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained model for embeddings.\n",
    "    - query_set: Query dataset.\n",
    "    - prototypes: Class prototypes.\n",
    "    - class_to_keyword: Mapping from class indices to keywords.\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted keywords.\n",
    "    - loss: Total loss for the query set.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    loss = 0.0\n",
    "\n",
    "    # Get embeddings for the query set\n",
    "    query_embeddings = model.predict(query_set)  # Shape: (batch_size, embedding_dim)\n",
    "    \n",
    "    for query_embedding in query_embeddings:\n",
    "        # Compute distances and find the closest prototype\n",
    "        distances = np.linalg.norm(prototypes - query_embedding, axis=1)\n",
    "        predicted_index = np.argmin(distances)  # Closest prototype index\n",
    "        predictions.append(class_to_keyword[predicted_index])  # Map to keyword\n",
    "        loss += np.min(distances)  # Sum of distances as the loss\n",
    "\n",
    "    return predictions, loss\n",
    "\n",
    "def prepare_dataset(audio_folder_path, labels, num_shots, num_query):\n",
    "    \"\"\"Prepare the few-shot dataset.\"\"\"\n",
    "    audio_files = glob.glob(os.path.join(audio_folder_path, \"*.mp3\"))\n",
    "    class_to_keyword, keyword_to_class = create_class_to_keyword_mapping(labels)\n",
    "    \n",
    "    dataset = prepare_few_shot_dataset(audio_files, labels, num_shots, num_query)\n",
    "    \n",
    "    return dataset, class_to_keyword, keyword_to_class\n",
    "\n",
    "def create_class_to_keyword_mapping(labels):\n",
    "    \"\"\"Creates a mapping from class indices to human-readable keywords.\"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_indices = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    class_to_keyword = {idx: label for idx, label in enumerate(label_encoder.classes_)}\n",
    "    keyword_to_class = {label: idx for idx, label in class_to_keyword.items()}\n",
    "    \n",
    "    return class_to_keyword, keyword_to_class\n",
    "\n",
    "# Assuming your dataset is in this folder\n",
    "audio_folder_path = \"cv-corpus-7.0-singleword/ta\"  # Update this to the location of your dataset\n",
    "#labels = [\"label1\", \"label2\", \"label3\"]  # Example labels\n",
    "num_shots = 5\n",
    "num_query = 15\n",
    "\n",
    "# Prepare dataset\n",
    "dataset, class_to_keyword, keyword_to_class = prepare_dataset(audio_folder_path, labels, num_shots, num_query)\n",
    "\n",
    "# Load the query set (new audio files)\n",
    "new_keyword_query_set = load_dataset(audio_folder_path)  # Load new query set\n",
    "new_keyword_query_set = np.expand_dims(new_keyword_query_set, axis=1)  # Shape: (batch_size, sequence_length, 128, 216, 3)\n",
    "\n",
    "# Assuming you already have a trained model\n",
    "model = build_model((128, 216, 3), LSTM_UNITS)  # LSTM_UNITS should be defined\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Get embeddings for the query set\n",
    "embeddings = model.predict(new_keyword_query_set)  # Get embeddings for the audio files\n",
    "\n",
    "# Compute prototypes for each class\n",
    "num_classes = len(np.unique(labels))\n",
    "prototypes = compute_prototypes(embeddings, labels, num_classes)\n",
    "\n",
    "# Perform few-shot inference and convert numeric predictions to keywords\n",
    "predicted_keywords, loss = few_shot_inference_with_keywords(model, new_keyword_query_set, prototypes, class_to_keyword)\n",
    "\n",
    "print(f\"Predicted Keywords: {predicted_keywords}, Loss: {loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
